#!/usr/bin/env python

#                  High-Level Reduction Functions
#           A part of the SNS Analysis Software Suite.
#
#                  Spallation Neutron Source
#          Oak Ridge National Laboratory, Oak Ridge TN.
#
#
#                             NOTICE
#
# For this software and its associated documentation, permission is granted
# to reproduce, prepare derivative works, and distribute copies to the public
# for any purpose and without fee.
#
# This material was prepared as an account of work sponsored by an agency of
# the United States Government.  Neither the United States Government nor the
# United States Department of Energy, nor any of their employees, makes any
# warranty, express or implied, or assumes any legal liability or
# responsibility for the accuracy, completeness, or usefulness of any
# information, apparatus, product, or process disclosed, or represents that
# its use would not infringe privately owned rights.
#

# $Id$

def filter_pixels(conf, data_som):

    return dr_lib.filter_pixels(data_som, conf.data_paths,
                                conf.starting_ids, conf.ending_ids)

def determine_background(conf, bkg_som, num_data_pixels):

    if conf.no_bkg:
        return None
    else:
        bkg_som1 = dr_lib.sum_all_spectra(bkg_som)
        if conf.verbose:
            print "Background counts:", dr_lib.integrate_axis(bkg_som1)
        ratio = (1.0 / float(len(bkg_som)), 0.0)
        return common_lib.mult_ncerr(bkg_som1, ratio)

def subtract_bkg_from_data(data_som, bkg_som):
    """Step 4. Subtract the background using function 3.7 with
    IeDXY(lambda) as data1 and IeBXY(lambda) as data2. The result is
    IebDXY(lambda)."""

    if bkg_som is None:
        return data_som
    else:
        return common_lib.sub_ncerr(data_som, bkg_som[0])

def scale_inc_spec_factor(conf, isf_som):
    """Step 6. Scale the incident spectrum by the geometry factor
    using function 3.1 with 1/IeM2(lambda) as data1 and G as a. The
    result is the effective incident spectrum factor,
    Iinc(lambda). Note: Iinc(lambda) in not a raw spectrum as noted by
    section 0."""

    if isf_som is None:
        return None
    elif conf.geom_factor is None:
        return isf_som
    else:
        return common_lib.div_ncerr(isf_som, conf.geom_factor)

def norm_data_by_inc_spec_factor(data_som, isf_som):
    """Step 8. Normalize using the incident spectrum factor using
    function 3.9 with IebDXY(lambda) as data1 and Iinc(lambda) as
    data2. The result is the reflectivity, R(lambda)."""
    
    if isf_som is None:
        return data_som
    else:
        return common_lib.div_ncerr(data_som, isf_som)

def combine_spectra(data_som):

    id = data_som[0].id
    data_som1 = dr_lib.sum_all_spectra(data_som)
    data_som1[0].id = id

    return data_som1

def run(config, tim):
    import sys

    import DST
    
    if config.data is None:
        raise RuntimeError("Need to pass a data filename to the driver "\
                           +"script.")

    if tim is not None:
        old_time = tim.getOldTime()

    so_axis = "time_of_flight"

    for i in xrange(config.num_data_files):
        if config.num_data_files == 1:
            file_name = config.data
        else:
            file_name = config.data[i]

        print "File:",file_name
            
        try:
            data_dst = DST.getInstance("application/x-NeXus", file_name) 
        except SystemError:
            print "ERROR: Failed to data read file %s" % file_name
            sys.exit(-1)

        if config.verbose:
            if config.num_data_files == 1:
                print "Reading data file"
            else:
                print "Reading data file %d" % i

        if i == 0:
            d_som1 = data_dst.getSOM(config.data_paths, so_axis)

            if config.verbose:
                print "# SO:",len(d_som1)
                print "# TOF:",len(d_som1[0])

            if tim is not None:
                tim.getTime(msg="After reading data: ")

            d_som1.attr_list["proton_charge"] = data_dst.getParameter("proton_charge")
        else:
            d_som_t = data_dst.getSOM(config.data_paths, so_axis)

            if tim is not None:
                tim.getTime(msg="After reading data: ")

            d_som1 = common_lib.add_ncerr(d_som_t, d_som1)

            if tim is not None:
                tim.getTime(msg="After adding spectra: ")

            del d_som_t

            if tim is not None:
                tim.getTime(msg="After SOM deletion")

        data_dst.release_resource()
        del data_dst

        if tim is not None:
            tim.getTime(msg="After resource release and DST deletion")

    if config.num_data_files == 1:
        main_data = config.data
    else:
        main_data = config.data[0]
    
    if config.verbose:
        print "Filtering specular and background pixels"

    if tim is not None:
        tim.getTime(False)

    (d_som2_D, d_som2_B) = filter_pixels(config, d_som1)

    if tim is not None:
        tim.getTime(msg="After filtering pixels: ")

    if config.verbose:
        print "Pixel counts:", len(d_som2_D), len(d_som2_B)

    if config.dump_specular:
        if tim is not None:
            tim.getTime(False)
        
        d_som2_D1 = dr_lib.sum_all_spectra(d_som2_D)

        if tim is not None:
            tim.getTime(msg="After summing signal spectra: ")
        if config.verbose:
            print "Signal counts:", dr_lib.integrate_axis(d_som2_D1)
        d_som2_D1[0].id = ("bank1", (0, 0))
        hlr_utils.write_file(main_data, "text/Spec", d_som2_D1,
                             output_ext="sdc", verbose=config.verbose,
                             message="combined specular TOF information")
        d_som2_D1 = None
        del d_som2_D1

    if config.verbose and not config.no_bkg:
        print "Determining background"

    if tim is not None:
        tim.getTime(False)

    B = determine_background(config, d_som2_B, len(d_som2_D))

    if tim is not None:
            tim.getTime(msg="After background determination: ")

    if not config.no_bkg:
        hlr_utils.write_file(main_data, "text/Spec", B,
                             output_ext="bkg", verbose=config.verbose,
                             message="combined background TOF information")
        
    if config.verbose and not config.no_bkg:
        print "Subtracting background"

    if tim is not None:
        tim.getTime(False)

    d_som3 = subtract_bkg_from_data(d_som2_D, B)

    if tim is not None:
        tim.getTime(msg="After subtracting background: ")

    d_som2_D = None
    d_som2_B = None
    del d_som2_D, d_som2_B

    if tim is not None:
        tim.getTime(False)

    d_som4 = combine_spectra(d_som3)

    if tim is not None:
        tim.getTime(msg="After combining signal spectra: ")

    del d_som3
    
    if config.dump_sub:
        hlr_utils.write_file(main_data, "text/Spec", d_som4,
                             output_ext="sub", verbose=config.verbose,
                             message="combined subtracted TOF information")

    if config.norm is not None:
        if config.verbose:
            print "Reading normalization file"

        norm_dst = DST.getInstance("application/x-NeXus", config.norm)
        n_som1 = norm_dst.getSOM(config.data_paths, so_axis,
                                 start_id=config.norm_starting_ids,
                                 end_id=config.norm_ending_ids)
        print "Norm Pixels:", len(n_som1)
        norm_dst.release_resource()
    else:
        n_som1 = None

    if config.norm is not None:
        n_som2 = combine_spectra(n_som1)
    else:
        n_som2 = None

    if config.dump_norm and config.norm is not None:
        hlr_utils.write_file(main_data, "text/Spec", n_som2,
                             output_ext="nom", verbose=config.verbose,
                             message="combined normalization TOF information")

    if config.verbose and config.norm is not None:
        print "Normalizing data"

    if tim is not None:
        tim.getTime(False)

    d_som5 = norm_data_by_inc_spec_factor(d_som4, n_som2)

    if tim is not None:
        tim.getTime(msg="After normalizing signal spectra: ")

    del d_som4

    if config.det_angle is None:
        d_som5.attr_list["detector_angle"] = (0.0, "degree")
    else:
        d_som5.attr_list["detector_angle"] = config.det_angle

    hlr_utils.write_file(config.output, "text/Spec", d_som5, replace=False,
                         verbose=config.verbose,
                         message="combined Reflectivity information")

    d_som5.attr_list["config"] = config

    hlr_utils.write_file(main_data, "text/rmd", d_som5,
                         output_ext="rmd", verbose=config.verbose,
                         message="metadata")

    if tim is not None:
        tim.setOldTime(old_time)
        tim.getTime(msg="Completing driver: ")

if __name__ == "__main__":
    import os
    
    import common_lib
    import dr_lib
    import hlr_utils
    
    # set up the options available
    parser = hlr_utils.SNSOptions("usage: %prog [options] <datafile>",
                                  inst="REF")

    # Add REF specific options
    parser.add_option("", "--data-paths", dest="data_paths",
                      help="Specify the comma separated list of detector data"\
                      +"paths and signals. Default is /entry/bank1,1")
    parser.set_defaults(data_paths="/entry/bank1,1")

    parser.add_option("", "--geom-factor", dest="geom_factor",
                      help="Specify the geometry factor G, err^2")
    
    parser.add_option("", "--det-angle", dest="det_angle",
                      help="Specify the detector inclination angle, err^2, "\
                      +"and units")

    parser.add_option("", "--starting-ids", dest="starting_ids",
                      help="Specify the comma separated list of i and j pixel"\
                      +" locations on the detector. This is inclusive.")

    parser.add_option("", "--ending-ids", dest="ending_ids",
                      help="Specify the comma separated list of i and j pixel"\
                      +" locations on the detector. This is inclusive.")

    parser.add_option("", "--norm-starting-ids", dest="norm_starting_ids",
                      help="Specify the comma separated list of i and j pixel"\
                      +" locations on the detector. This is inclusive.")

    parser.add_option("", "--norm-ending-ids", dest="norm_ending_ids",
                      help="Specify the comma separated list of i and j pixel"\
                      +" locations on the detector. This is inclusive.")

    parser.add_option("", "--dump-specular", action="store_true",
                      dest="dump_specular",
                      help="Flag to dump the combined specular TOF "\
                      +"information")
    parser.set_defaults(dump_specular=False)

    parser.add_option("", "--dump-norm", action="store_true",
                      dest="dump_norm",
                      help="Flag to dump the combined normalization TOF "\
                      +"information")
    parser.set_defaults(dump_norm=False)

    parser.add_option("", "--dump-sub", action="store_true",
                      dest="dump_sub",
                      help="Flag to dump the combined subtracted TOF "\
                      +"information")
    parser.set_defaults(dump_sub=False)

    parser.add_option("", "--dump-all", action="store_true", dest="dump_all",
                      help="Flag to dump combined information")
    parser.set_defaults(dump_all=False)

    parser.add_option("", "--no-bkg", action="store_true", dest="no_bkg",
                      help="Flag to turn off background estimation and "\
                      +"subtraction")
    parser.set_defaults(no_bkg=False)

    parser.add_option("", "--det-geom", dest="det_geom",
                      help="Specify the detector geometry file")

    parser.add_option("", "--timing", action="store_true", dest="timing",
                      help="Flag to turn on timing of code")
    parser.set_defaults(timing=False)

    (options, args) = parser.parse_args()
    
    # set up the configuration
    configure = hlr_utils.Configure()
    
    # get the datafile name and check it
    configure.num_data_files = len(args)
    
    if configure.num_data_files == 1:
        configure.data = args[0]
        if not hlr_utils.file_exists(configure.data):
            parser.error("Data file [%s] does not exist" % configure.data)
    elif configure.num_data_files > 1:
        import copy
        tmplist = copy.deepcopy(args)
        for infile in tmplist:
            if not hlr_utils.file_exists(infile):
                print "Data file [%s] does not exist, removing from list" % \
                      infile
                args.remove(infile)
                configure.num_data_files -= 1
            else:
                pass

        del tmplist
        if configure.num_data_files == 0:
            raise RuntimeError("No valid files are present. Reduction cannot "\
                               +"be run.")
        else:
            configure.data = args
    else:
        parser.error("Did not specify a datafile")

    # create the output file name if there isn't one supplied
    if options.output is not None:
        configure.output = options.output
    else:
        if configure.num_data_files == 1:
            dfile_name = configure.data
        else:
            dfile_name = configure.data[0]
        outfile = os.path.basename(dfile_name)
        path = os.path.join(os.getcwd(), outfile)
        configure.output = hlr_utils.ext_replace(path, "nxs", "txt")
        print "Using %s as output file" % configure.output

    # set the verbosity
    configure.verbose = options.verbose

    configure.norm = hlr_utils.fix_filename(options.norm)
    if configure.norm is not None:
        if not hlr_utils.file_exists(configure.norm):
            parser.error("Normalization file [%s] does not exist" \
                         % configure.norm)
        else:
            pass
    else:
        pass

    configure.det_geom = hlr_utils.fix_filename(options.det_geom)
    if configure.det_geom is not None:
        if not hlr_utils.file_exists(configure.det_geom):
            parser.error("Detector geometry file [%s] does not exist" \
                         % configure.det_geom)
        else:
            pass
    else:
        pass

    # set the data paths
    configure.data_paths = hlr_utils.create_data_paths(options.data_paths)

    if options.geom_factor is not None:
        configure.geom_factor = hlr_utils.split_values(options.geom_factor)
    else:
        configure.geom_factor = options.geom_factor

    if options.det_angle is not None:
        configure.det_angle = hlr_utils.split_values(options.det_angle)
    else:
        configure.det_angle = options.det_angle

    # set the starting ids
    if options.starting_ids is not None:
        configure.starting_ids = hlr_utils.create_id_pairs(\
            options.starting_ids,\
            options.data_paths)
    else:
        configure.starting_ids = options.starting_ids

    # set the ending ids
    if options.ending_ids is not None:
        configure.ending_ids = hlr_utils.create_id_pairs(options.ending_ids,
                                                         options.data_paths,
                                                         inc=True)
    else:
        configure.ending_ids = options.ending_ids

    # set the norm_starting ids
    if options.norm_starting_ids is not None:
        configure.norm_starting_ids = hlr_utils.create_id_pairs(\
            options.norm_starting_ids,\
            options.data_paths)
    else:
        configure.norm_starting_ids = configure.starting_ids

    # set the norm_ending ids
    if options.norm_ending_ids is not None:
        configure.norm_ending_ids = hlr_utils.create_id_pairs(\
            options.norm_ending_ids,
            options.data_paths, inc=True)
    else:
        configure.norm_ending_ids = configure.ending_ids

    # set the ability to turn off background estimation and subtraction
    configure.no_bkg = options.no_bkg

    # set the ability to dump the combined specular TOF information
    configure.dump_specular = options.dump_specular

    # set the ability to dump the combined normalization TOF information
    configure.dump_norm = options.dump_norm

    # set the ability to dump the combined subtracted TOF information
    configure.dump_sub = options.dump_sub

    if options.dump_all:
        configure.dump_specular = True
        configure.dump_sub = True
        configure.dump_norm = True


    if options.timing:
        import sns_timing
        timer = sns_timing.DiffTime()
    else:
        timer = None
        
    # run the program
    run(configure, timer)

